{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import applications\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers\n",
    "from PIL import Image\n",
    "from keras.models import load_model\n",
    "from keras import models\n",
    "from keras import layers\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "path = os.getcwd()\n",
    "img_width, img_height = 256, 256\n",
    "train_data_dir = os.path.join(path,'val256','train')\n",
    "validation_data_dir = os.path.join(path,'val256','val')\n",
    "test_dir=os.path.join(path,'test256')\n",
    "nb_train_samples =573\n",
    "nb_validation_samples = 27\n",
    "batch_size = 1\n",
    "#epochs = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vgg = applications.VGG19(weights = \"imagenet\", include_top=False, input_shape = (img_width, img_height, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#downloading VGG model\n",
    "vgg = applications.VGG16(weights = \"imagenet\", include_top=False, input_shape = (img_width, img_height, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#freezing last layers\n",
    "for layer in vgg.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 573 images belonging to 2 classes.\n",
      "Found 27 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "#generation of data\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale = 1./255,\n",
    "    #horizontal_flip = True,\n",
    "    #fill_mode = \"nearest\",\n",
    "    #zoom_range = 0.3,\n",
    "    #width_shift_range = 0.3,\n",
    "    #height_shift_range=0.3,\n",
    "    #rotation_range=30)\n",
    ")\n",
    "val_datagen = ImageDataGenerator(\n",
    "    rescale = 1./255,\n",
    "    #horizontal_flip = True,\n",
    "    #fill_mode = \"nearest\",\n",
    "    #zoom_range = 0.3,\n",
    "    #width_shift_range = 0.3,\n",
    "    #height_shift_range=0.3,\n",
    "    #rotation_range=30)\n",
    ")\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size = (img_height, img_width),\n",
    "    batch_size = batch_size, \n",
    "    shuffle = True,\n",
    "    class_mode = \"categorical\")\n",
    "\n",
    "validation_generator = val_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size = (img_height, img_width),\n",
    "    batch_size = batch_size, \n",
    "    shuffle = True,\n",
    "    class_mode = \"categorical\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2365"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting features from images (for train data and validation data)\n",
    "train_features = np.zeros(shape=(nb_train_samples, 8, 8, 512))\n",
    "train_labels = np.zeros(shape=(nb_train_samples,2))\n",
    "\n",
    "validation_features = np.zeros(shape=(nb_validation_samples, 8, 8, 512))\n",
    "validation_labels = np.zeros(shape=(nb_validation_samples,2))\n",
    "\n",
    "i = 0\n",
    "for inputs_batch, labels_batch in train_generator:\n",
    "    features_batch = vgg.predict(inputs_batch)\n",
    "    train_features[i * batch_size : (i + 1) * batch_size] = features_batch\n",
    "    train_labels[i * batch_size : (i + 1) * batch_size] = labels_batch\n",
    "    i += 1\n",
    "    if i * batch_size >= nb_train_samples:\n",
    "        break\n",
    "i = 0\n",
    "for inputs_batch, labels_batch in validation_generator:\n",
    "    features_batch_val = vgg.predict(inputs_batch)\n",
    "    validation_features[i * batch_size : (i + 1) * batch_size] = features_batch_val\n",
    "    validation_labels[i * batch_size : (i + 1) * batch_size] = labels_batch\n",
    "    i += 1\n",
    "    if i * batch_size >= nb_validation_samples:\n",
    "        break\n",
    "         \n",
    "train_features = np.reshape(train_features, (nb_train_samples, 8 * 8 * 512))\n",
    "validation_features = np.reshape(validation_features, (nb_validation_samples, 8 * 8 * 512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg16 (Model)                (None, 8, 8, 512)         14714688  \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 32768)             0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 128)               4194432   \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 2)                 258       \n",
      "=================================================================\n",
      "Total params: 18,925,890\n",
      "Trainable params: 4,211,202\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#constructing model over VGG\n",
    "model = models.Sequential()\n",
    "model.add(vgg)\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "#model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "#model.add(layers.Dropout(0.5))\n",
    "#model.add(layers.Dense(128, activation='relu'))\n",
    "#model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(2, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "573/573 [==============================] - 736s 1s/step - loss: 0.5669 - acc: 0.8080 - val_loss: 0.1142 - val_acc: 0.9259\n",
      "Epoch 2/5\n",
      "573/573 [==============================] - 336s 586ms/step - loss: 0.1051 - acc: 0.9546 - val_loss: 0.0022 - val_acc: 1.0000\n",
      "Epoch 3/5\n",
      "136/573 [======>.......................] - ETA: 4:07 - loss: 0.0498 - acc: 0.9853"
     ]
    }
   ],
   "source": [
    "#fitting\n",
    "model.compile(optimizer=optimizers.RMSprop(lr=1e-4),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['acc'])\n",
    " \n",
    "history = model.fit_generator(\n",
    "      train_generator,\n",
    "      steps_per_epoch=train_generator.samples/train_generator.batch_size ,\n",
    "      epochs=7,\n",
    "      validation_data=validation_generator,\n",
    "      validation_steps=validation_generator.samples/validation_generator.batch_size,\n",
    "      verbose=1)\n",
    "\n",
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#downloading our model if already fitted\n",
    "model = load_model('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub=pd.read_csv('sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/denis/anaconda3/envs/tensorflow/lib/python3.6/site-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if sys.path[0] == '':\n",
      "/home/denis/anaconda3/envs/tensorflow/lib/python3.6/site-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "#making predictions for test directory\n",
    "\n",
    "for k in range(0,400):\n",
    "    t='{0:03}'.format(k)\n",
    "    image=Image.open(test_dir+'/'+str(t)+'.jpg')\n",
    "    im = np.array(image)/255.\n",
    "    im = im.reshape(1, im.shape[0], im.shape[1], im.shape[2])\n",
    "    prediction = model.predict_classes(im)\n",
    "    if prediction == [0]:\n",
    "        sub.label[k]='cat'\n",
    "    else:\n",
    "        sub.label[k]='dog'\n",
    "        \n",
    "sub.to_csv('out.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
